### [3.1 Broker Configs](https://kafka.apache.org/documentation/#brokerconfigs)

The essential configurations are the following:

- `broker.id`
- `log.dirs`
- `zookeeper.connect`
  - `카프카와 주키퍼를 연결할 포트`
  - `zookeeper.connect=zoo1:2181,zoo2:2181,zoo3:2181`

Topic-level configurations and defaults are discussed in more detail [below](https://kafka.apache.org/documentation/#topicconfigs).

- #### [advertised.listeners](https://kafka.apache.org/documentation/#brokerconfigs_advertised.listeners)
  
  - 클라이언트가 사용할 리스너 정보
  
  - `advertised.listeners=INSIDE://broker1.internal:9093,OUTSIDE://broker1.example.com:9094`
  
  - 0.0.0.0 불가
  
  - 기본값 null
  
  |               |            |
  | ------------- | ---------- |
  | Type:         | string     |
  | Default:      | null       |
  | Valid Values: |            |
  | Importance:   | high       |
  | Update Mode:  | per-broker |

- #### [auto.create.topics.enable](https://kafka.apache.org/documentation/#brokerconfigs_auto.create.topics.enable)
  
  등록되지 않은 토픽 생성
  
  |               |           |
  | ------------- | --------- |
  | Type:         | boolean   |
  | Default:      | true      |
  | Valid Values: |           |
  | Importance:   | high      |
  | Update Mode:  | read-only |

- #### [auto.leader.rebalance.enable](https://kafka.apache.org/documentation/#brokerconfigs_auto.leader.rebalance.enable)
  
  카프카 센티넬 옵션
  
  리더 컨디션 파악후 다른 레플리카를 리더로
  
  |               |           |
  | ------------- | --------- |
  | Type:         | boolean   |
  | Default:      | true      |
  | Valid Values: |           |
  | Importance:   | high      |
  | Update Mode:  | read-only |

- #### [background.threads](https://kafka.apache.org/documentation/#brokerconfigs_background.threads)
  
  The number of threads to use for various background processing tasks
  
  |               |              |
  | ------------- | ------------ |
  | Type:         | int          |
  | Default:      | 10           |
  | Valid Values: | [1,...]      |
  | Importance:   | high         |
  | Update Mode:  | cluster-wide |

- #### [broker.id](https://kafka.apache.org/documentation/#brokerconfigs_broker.id)
  
  `broker.id`는 Kafka 클러스터 내 각 브로커를 **고유하게 식별하는 ID**입니다. 이 값이 설정되지 않으면 Kafka가 자동으로 고유한 `broker.id`를 생성합니다. 다만, ZooKeeper와 충돌을 피하기 위해 자동 생성된 `broker.id`는 `reserved.broker.max.id + 1`부터 시작합니다.
  
  |               |           |
  | ------------- | --------- |
  | Type:         | int       |
  | Default:      | -1        |
  | Valid Values: |           |
  | Importance:   | high      |
  | Update Mode:  | read-only |

- #### [compression.type](https://kafka.apache.org/documentation/#brokerconfigs_compression.type)
  
  압축 형식은 `gzip`, `snappy`, `lz4`, `zstd` 등과 같은 표준 압축 코덱을 사용할 수 있습니다. `uncompressed`를 사용하면 압축을 사용하지 않게 되며, `producer`를 설정하면 **프로듀서가 설정한 압축 방식**을 그대로 사용합니다.
  
  압축을 사용하면 디스크 사용량을 줄이고 네트워크 성능을 향상시킬 수 있지만, CPU 사용량이 늘어날 수 있습니다.
  
  `compression.type=gzip  # gzip 압축 사용`
  
  |               |                                                   |
  | ------------- | ------------------------------------------------- |
  | Type:         | string                                            |
  | Default:      | producer                                          |
  | Valid Values: | [uncompressed, zstd, lz4, snappy, gzip, producer] |
  | Importance:   | high                                              |
  | Update Mode:  | cluster-wide                                      |

- #### [control.plane.listener.name](https://kafka.apache.org/documentation/#brokerconfigs_control.plane.listener.name)
  
  Name of listener used for communication between controller and brokers. A broker will use the `control.plane.listener.name` to locate the endpoint in listeners list, to listen for connections from the controller. For example, if a broker's config is:  
  `listeners = INTERNAL://192.1.1.8:9092, EXTERNAL://10.1.1.5:9093, CONTROLLER://192.1.1.8:9094listener.security.protocol.map = INTERNAL:PLAINTEXT, EXTERNAL:SSL, CONTROLLER:SSLcontrol.plane.listener.name = CONTROLLER`  
  On startup, the broker will start listening on "192.1.1.8:9094" with security protocol "SSL".  
  On the controller side, when it discovers a broker's published endpoints through ZooKeeper, it will use the `control.plane.listener.name` to find the endpoint, which it will use to establish connection to the broker.  
  For example, if the broker's published endpoints on ZooKeeper are:  
  `"endpoints" : ["INTERNAL://broker1.example.com:9092","EXTERNAL://broker1.example.com:9093","CONTROLLER://broker1.example.com:9094"]`  
  and the controller's config is:  
  `listener.security.protocol.map = INTERNAL:PLAINTEXT, EXTERNAL:SSL, CONTROLLER:SSLcontrol.plane.listener.name = CONTROLLER`  
  then the controller will use "broker1.example.com:9094" with security protocol "SSL" to connect to the broker.  
  If not explicitly configured, the default value will be null and there will be no dedicated endpoints for controller connections.  
  If explicitly configured, the value cannot be the same as the value of `inter.broker.listener.name`.
  
  |               |           |
  | ------------- | --------- |
  | Type:         | string    |
  | Default:      | null      |
  | Valid Values: |           |
  | Importance:   | high      |
  | Update Mode:  | read-only |

- #### [controller.listener.names](https://kafka.apache.org/documentation/#brokerconfigs_controller.listener.names)
  
  A comma-separated list of the names of the listeners used by the controller. This is required if running in KRaft mode. When communicating with the controller quorum, the broker will always use the first listener in this list.  
  Note: The ZooKeeper-based controller should not set this configuration.
  
  |               |           |
  | ------------- | --------- |
  | Type:         | string    |
  | Default:      | null      |
  | Valid Values: |           |
  | Importance:   | high      |
  | Update Mode:  | read-only |

- #### [controller.quorum.bootstrap.servers](https://kafka.apache.org/documentation/#brokerconfigs_controller.quorum.bootstrap.servers)
  
  List of endpoints to use for bootstrapping the cluster metadata. The endpoints are specified in comma-separated list of `{host}:{port}` entries. For example: `localhost:9092,localhost:9093,localhost:9094`.
  
  |               |                |
  | ------------- | -------------- |
  | Type:         | list           |
  | Default:      | ""             |
  | Valid Values: | non-empty list |
  | Importance:   | high           |
  | Update Mode:  | read-only      |

- #### [controller.quorum.election.backoff.max.ms](https://kafka.apache.org/documentation/#brokerconfigs_controller.quorum.election.backoff.max.ms)
  
  Maximum time in milliseconds before starting new elections. This is used in the binary exponential backoff mechanism that helps prevent gridlocked elections
  
  |               |                 |
  | ------------- | --------------- |
  | Type:         | int             |
  | Default:      | 1000 (1 second) |
  | Valid Values: |                 |
  | Importance:   | high            |
  | Update Mode:  | read-only       |

- #### [controller.quorum.election.timeout.ms](https://kafka.apache.org/documentation/#brokerconfigs_controller.quorum.election.timeout.ms)
  
  Maximum time in milliseconds to wait without being able to fetch from the leader before triggering a new election
  
  |               |                 |
  | ------------- | --------------- |
  | Type:         | int             |
  | Default:      | 1000 (1 second) |
  | Valid Values: |                 |
  | Importance:   | high            |
  | Update Mode:  | read-only       |

- #### [controller.quorum.fetch.timeout.ms](https://kafka.apache.org/documentation/#brokerconfigs_controller.quorum.fetch.timeout.ms)
  
  Maximum time without a successful fetch from the current leader before becoming a candidate and triggering an election for voters; Maximum time a leader can go without receiving valid fetch or fetchSnapshot request from a majority of the quorum before resigning.
  
  |               |                  |
  | ------------- | ---------------- |
  | Type:         | int              |
  | Default:      | 2000 (2 seconds) |
  | Valid Values: |                  |
  | Importance:   | high             |
  | Update Mode:  | read-only        |

- #### [controller.quorum.voters](https://kafka.apache.org/documentation/#brokerconfigs_controller.quorum.voters)
  
  Map of id/endpoint information for the set of voters in a comma-separated list of `{id}@{host}:{port}` entries. For example: `1@localhost:9092,2@localhost:9093,3@localhost:9094`
  
  |               |                |
  | ------------- | -------------- |
  | Type:         | list           |
  | Default:      | ""             |
  | Valid Values: | non-empty list |
  | Importance:   | high           |
  | Update Mode:  | read-only      |

- #### [delete.topic.enable](https://kafka.apache.org/documentation/#brokerconfigs_delete.topic.enable)
  
  Enables delete topic. Delete topic through the admin tool will have no effect if this config is turned off
  
  |               |           |
  | ------------- | --------- |
  | Type:         | boolean   |
  | Default:      | true      |
  | Valid Values: |           |
  | Importance:   | high      |
  | Update Mode:  | read-only |

- #### [early.start.listeners](https://kafka.apache.org/documentation/#brokerconfigs_early.start.listeners)
  
  A comma-separated list of listener names which may be started before the authorizer has finished initialization. This is useful when the authorizer is dependent on the cluster itself for bootstrapping, as is the case for the StandardAuthorizer (which stores ACLs in the metadata log.) By default, all listeners included in controller.listener.names will also be early start listeners. A listener should not appear in this list if it accepts external traffic.
  
  |               |           |
  | ------------- | --------- |
  | Type:         | string    |
  | Default:      | null      |
  | Valid Values: |           |
  | Importance:   | high      |
  | Update Mode:  | read-only |

- #### [eligible.leader.replicas.enable](https://kafka.apache.org/documentation/#brokerconfigs_eligible.leader.replicas.enable)
  
  Enable the Eligible leader replicas
  
  |               |           |
  | ------------- | --------- |
  | Type:         | boolean   |
  | Default:      | false     |
  | Valid Values: |           |
  | Importance:   | high      |
  | Update Mode:  | read-only |

- #### [leader.imbalance.check.interval.seconds](https://kafka.apache.org/documentation/#brokerconfigs_leader.imbalance.check.interval.seconds)
  
  The frequency with which the partition rebalance check is triggered by the controller
  
  |               |           |
  | ------------- | --------- |
  | Type:         | long      |
  | Default:      | 300       |
  | Valid Values: | [1,...]   |
  | Importance:   | high      |
  | Update Mode:  | read-only |

- #### [leader.imbalance.per.broker.percentage](https://kafka.apache.org/documentation/#brokerconfigs_leader.imbalance.per.broker.percentage)
  
  The ratio of leader imbalance allowed per broker. The controller would trigger a leader balance if it goes above this value per broker. The value is specified in percentage.
  
  |               |           |
  | ------------- | --------- |
  | Type:         | int       |
  | Default:      | 10        |
  | Valid Values: |           |
  | Importance:   | high      |
  | Update Mode:  | read-only |

- #### [listeners](https://kafka.apache.org/documentation/#brokerconfigs_listeners)
  
  Listener List - Comma-separated list of URIs we will listen on and the listener names. If the listener name is not a security protocol, `listener.security.protocol.map` must also be set.  
  Listener names and port numbers must be unique unless %n one listener is an IPv4 address and the other listener is %n an IPv6 address (for the same port).%n Specify hostname as 0.0.0.0 to bind to all interfaces.%n Leave hostname empty to bind to default interface.%n Examples of legal listener lists:%n `PLAINTEXT://myhost:9092,SSL://:9091`%n `CLIENT://0.0.0.0:9092,REPLICATION://localhost:9093`%n `PLAINTEXT://127.0.0.1:9092,SSL://[::1]:9092`%n
  
  |               |                   |
  | ------------- | ----------------- |
  | Type:         | string            |
  | Default:      | PLAINTEXT://:9092 |
  | Valid Values: |                   |
  | Importance:   | high              |
  | Update Mode:  | per-broker        |

- #### [log.dir](https://kafka.apache.org/documentation/#brokerconfigs_log.dir)
  
  The directory in which the log data is kept (supplemental for log.dirs property)
  
  |               |                 |
  | ------------- | --------------- |
  | Type:         | string          |
  | Default:      | /tmp/kafka-logs |
  | Valid Values: |                 |
  | Importance:   | high            |
  | Update Mode:  | read-only       |

- #### [log.dirs](https://kafka.apache.org/documentation/#brokerconfigs_log.dirs)
  
  A comma-separated list of the directories where the log data is stored. If not set, the value in log.dir is used.
  
  |               |           |
  | ------------- | --------- |
  | Type:         | string    |
  | Default:      | null      |
  | Valid Values: |           |
  | Importance:   | high      |
  | Update Mode:  | read-only |

- #### [log.flush.interval.messages](https://kafka.apache.org/documentation/#brokerconfigs_log.flush.interval.messages)
  
  The number of messages accumulated on a log partition before messages are flushed to disk.
  
  |               |                     |
  | ------------- | ------------------- |
  | Type:         | long                |
  | Default:      | 9223372036854775807 |
  | Valid Values: | [1,...]             |
  | Importance:   | high                |
  | Update Mode:  | cluster-wide        |

- #### [log.flush.interval.ms](https://kafka.apache.org/documentation/#brokerconfigs_log.flush.interval.ms)
  
  The maximum time in ms that a message in any topic is kept in memory before flushed to disk. If not set, the value in log.flush.scheduler.interval.ms is used
  
  |               |              |
  | ------------- | ------------ |
  | Type:         | long         |
  | Default:      | null         |
  | Valid Values: |              |
  | Importance:   | high         |
  | Update Mode:  | cluster-wide |

- #### [log.flush.offset.checkpoint.interval.ms](https://kafka.apache.org/documentation/#brokerconfigs_log.flush.offset.checkpoint.interval.ms)
  
  The frequency with which we update the persistent record of the last flush which acts as the log recovery point.
  
  |               |                  |
  | ------------- | ---------------- |
  | Type:         | int              |
  | Default:      | 60000 (1 minute) |
  | Valid Values: | [0,...]          |
  | Importance:   | high             |
  | Update Mode:  | read-only        |

- #### [log.flush.scheduler.interval.ms](https://kafka.apache.org/documentation/#brokerconfigs_log.flush.scheduler.interval.ms)
  
  The frequency in ms that the log flusher checks whether any log needs to be flushed to disk
  
  |               |                     |
  | ------------- | ------------------- |
  | Type:         | long                |
  | Default:      | 9223372036854775807 |
  | Valid Values: |                     |
  | Importance:   | high                |
  | Update Mode:  | read-only           |

- #### [log.flush.start.offset.checkpoint.interval.ms](https://kafka.apache.org/documentation/#brokerconfigs_log.flush.start.offset.checkpoint.interval.ms)
  
  The frequency with which we update the persistent record of log start offset
  
  |               |                  |
  | ------------- | ---------------- |
  | Type:         | int              |
  | Default:      | 60000 (1 minute) |
  | Valid Values: | [0,...]          |
  | Importance:   | high             |
  | Update Mode:  | read-only        |

- #### [log.retention.bytes](https://kafka.apache.org/documentation/#brokerconfigs_log.retention.bytes)
  
  The maximum size of the log before deleting it
  
  |               |              |
  | ------------- | ------------ |
  | Type:         | long         |
  | Default:      | -1           |
  | Valid Values: |              |
  | Importance:   | high         |
  | Update Mode:  | cluster-wide |

- #### [log.retention.hours](https://kafka.apache.org/documentation/#brokerconfigs_log.retention.hours)
  
  The number of hours to keep a log file before deleting it (in hours), tertiary to log.retention.ms property
  
  |               |           |
  | ------------- | --------- |
  | Type:         | int       |
  | Default:      | 168       |
  | Valid Values: |           |
  | Importance:   | high      |
  | Update Mode:  | read-only |

- #### [log.retention.minutes](https://kafka.apache.org/documentation/#brokerconfigs_log.retention.minutes)
  
  The number of minutes to keep a log file before deleting it (in minutes), secondary to log.retention.ms property. If not set, the value in log.retention.hours is used
  
  |               |           |
  | ------------- | --------- |
  | Type:         | int       |
  | Default:      | null      |
  | Valid Values: |           |
  | Importance:   | high      |
  | Update Mode:  | read-only |

- #### [log.retention.ms](https://kafka.apache.org/documentation/#brokerconfigs_log.retention.ms)
  
  The number of milliseconds to keep a log file before deleting it (in milliseconds), If not set, the value in log.retention.minutes is used. If set to -1, no time limit is applied.
  
  |               |              |
  | ------------- | ------------ |
  | Type:         | long         |
  | Default:      | null         |
  | Valid Values: |              |
  | Importance:   | high         |
  | Update Mode:  | cluster-wide |

- #### [log.roll.hours](https://kafka.apache.org/documentation/#brokerconfigs_log.roll.hours)
  
  The maximum time before a new log segment is rolled out (in hours), secondary to log.roll.ms property
  
  |               |           |
  | ------------- | --------- |
  | Type:         | int       |
  | Default:      | 168       |
  | Valid Values: | [1,...]   |
  | Importance:   | high      |
  | Update Mode:  | read-only |

- #### [log.roll.jitter.hours](https://kafka.apache.org/documentation/#brokerconfigs_log.roll.jitter.hours)
  
  The maximum jitter to subtract from logRollTimeMillis (in hours), secondary to log.roll.jitter.ms property
  
  |               |           |
  | ------------- | --------- |
  | Type:         | int       |
  | Default:      | 0         |
  | Valid Values: | [0,...]   |
  | Importance:   | high      |
  | Update Mode:  | read-only |

- #### [log.roll.jitter.ms](https://kafka.apache.org/documentation/#brokerconfigs_log.roll.jitter.ms)
  
  The maximum jitter to subtract from logRollTimeMillis (in milliseconds). If not set, the value in log.roll.jitter.hours is used
  
  |               |              |
  | ------------- | ------------ |
  | Type:         | long         |
  | Default:      | null         |
  | Valid Values: |              |
  | Importance:   | high         |
  | Update Mode:  | cluster-wide |

- #### [log.roll.ms](https://kafka.apache.org/documentation/#brokerconfigs_log.roll.ms)
  
  The maximum time before a new log segment is rolled out (in milliseconds). If not set, the value in log.roll.hours is used
  
  |               |              |
  | ------------- | ------------ |
  | Type:         | long         |
  | Default:      | null         |
  | Valid Values: |              |
  | Importance:   | high         |
  | Update Mode:  | cluster-wide |

- #### [log.segment.bytes](https://kafka.apache.org/documentation/#brokerconfigs_log.segment.bytes)
  
  The maximum size of a single log file
  
  |               |                         |
  | ------------- | ----------------------- |
  | Type:         | int                     |
  | Default:      | 1073741824 (1 gibibyte) |
  | Valid Values: | [14,...]                |
  | Importance:   | high                    |
  | Update Mode:  | cluster-wide            |

- #### [log.segment.delete.delay.ms](https://kafka.apache.org/documentation/#brokerconfigs_log.segment.delete.delay.ms)
  
  The amount of time to wait before deleting a file from the filesystem. If the value is 0 and there is no file to delete, the system will wait 1 millisecond. Low value will cause busy waiting
  
  |               |                  |
  | ------------- | ---------------- |
  | Type:         | long             |
  | Default:      | 60000 (1 minute) |
  | Valid Values: | [0,...]          |
  | Importance:   | high             |
  | Update Mode:  | cluster-wide     |

- #### [message.max.bytes](https://kafka.apache.org/documentation/#brokerconfigs_message.max.bytes)
  
  The largest record batch size allowed by Kafka (after compression if compression is enabled). If this is increased and there are consumers older than 0.10.2, the consumers' fetch size must also be increased so that they can fetch record batches this large. In the latest message format version, records are always grouped into batches for efficiency. In previous message format versions, uncompressed records are not grouped into batches and this limit only applies to a single record in that case.This can be set per topic with the topic level `max.message.bytes` config.
  
  |               |              |
  | ------------- | ------------ |
  | Type:         | int          |
  | Default:      | 1048588      |
  | Valid Values: | [0,...]      |
  | Importance:   | high         |
  | Update Mode:  | cluster-wide |

- #### [metadata.log.dir](https://kafka.apache.org/documentation/#brokerconfigs_metadata.log.dir)
  
  This configuration determines where we put the metadata log for clusters in KRaft mode. If it is not set, the metadata log is placed in the first log directory from log.dirs.
  
  |               |           |
  | ------------- | --------- |
  | Type:         | string    |
  | Default:      | null      |
  | Valid Values: |           |
  | Importance:   | high      |
  | Update Mode:  | read-only |

- #### [metadata.log.max.record.bytes.between.snapshots](https://kafka.apache.org/documentation/#brokerconfigs_metadata.log.max.record.bytes.between.snapshots)
  
  This is the maximum number of bytes in the log between the latest snapshot and the high-watermark needed before generating a new snapshot. The default value is 20971520. To generate snapshots based on the time elapsed, see the `metadata.log.max.snapshot.interval.ms` configuration. The Kafka node will generate a snapshot when either the maximum time interval is reached or the maximum bytes limit is reached.
  
  |               |           |
  | ------------- | --------- |
  | Type:         | long      |
  | Default:      | 20971520  |
  | Valid Values: | [1,...]   |
  | Importance:   | high      |
  | Update Mode:  | read-only |

- #### [metadata.log.max.snapshot.interval.ms](https://kafka.apache.org/documentation/#brokerconfigs_metadata.log.max.snapshot.interval.ms)
  
  This is the maximum number of milliseconds to wait to generate a snapshot if there are committed records in the log that are not included in the latest snapshot. A value of zero disables time based snapshot generation. The default value is 3600000. To generate snapshots based on the number of metadata bytes, see the `metadata.log.max.record.bytes.between.snapshots` configuration. The Kafka node will generate a snapshot when either the maximum time interval is reached or the maximum bytes limit is reached.
  
  |               |                  |
  | ------------- | ---------------- |
  | Type:         | long             |
  | Default:      | 3600000 (1 hour) |
  | Valid Values: | [0,...]          |
  | Importance:   | high             |
  | Update Mode:  | read-only        |

- #### [metadata.log.segment.bytes](https://kafka.apache.org/documentation/#brokerconfigs_metadata.log.segment.bytes)
  
  The maximum size of a single metadata log file.
  
  |               |                         |
  | ------------- | ----------------------- |
  | Type:         | int                     |
  | Default:      | 1073741824 (1 gibibyte) |
  | Valid Values: | [12,...]                |
  | Importance:   | high                    |
  | Update Mode:  | read-only               |

- #### [metadata.log.segment.ms](https://kafka.apache.org/documentation/#brokerconfigs_metadata.log.segment.ms)
  
  The maximum time before a new metadata log file is rolled out (in milliseconds).
  
  |               |                    |
  | ------------- | ------------------ |
  | Type:         | long               |
  | Default:      | 604800000 (7 days) |
  | Valid Values: |                    |
  | Importance:   | high               |
  | Update Mode:  | read-only          |

- #### [metadata.max.retention.bytes](https://kafka.apache.org/documentation/#brokerconfigs_metadata.max.retention.bytes)
  
  The maximum combined size of the metadata log and snapshots before deleting old snapshots and log files. Since at least one snapshot must exist before any logs can be deleted, this is a soft limit.
  
  |               |                           |
  | ------------- | ------------------------- |
  | Type:         | long                      |
  | Default:      | 104857600 (100 mebibytes) |
  | Valid Values: |                           |
  | Importance:   | high                      |
  | Update Mode:  | read-only                 |

- #### [metadata.max.retention.ms](https://kafka.apache.org/documentation/#brokerconfigs_metadata.max.retention.ms)
  
  The number of milliseconds to keep a metadata log file or snapshot before deleting it. Since at least one snapshot must exist before any logs can be deleted, this is a soft limit.
  
  |               |                    |
  | ------------- | ------------------ |
  | Type:         | long               |
  | Default:      | 604800000 (7 days) |
  | Valid Values: |                    |
  | Importance:   | high               |
  | Update Mode:  | read-only          |

- #### [min.insync.replicas](https://kafka.apache.org/documentation/#brokerconfigs_min.insync.replicas)
  
  When a producer sets acks to "all" (or "-1"), `min.insync.replicas` specifies the minimum number of replicas that must acknowledge a write for the write to be considered successful. If this minimum cannot be met, then the producer will raise an exception (either `NotEnoughReplicas` or `NotEnoughReplicasAfterAppend`).  
  When used together, `min.insync.replicas` and acks allow you to enforce greater durability guarantees. A typical scenario would be to create a topic with a replication factor of 3, set `min.insync.replicas` to 2, and produce with acks of "all". This will ensure that the producer raises an exception if a majority of replicas do not receive a write.
  
  |               |              |
  | ------------- | ------------ |
  | Type:         | int          |
  | Default:      | 1            |
  | Valid Values: | [1,...]      |
  | Importance:   | high         |
  | Update Mode:  | cluster-wide |

- #### [node.id](https://kafka.apache.org/documentation/#brokerconfigs_node.id)
  
  The node ID associated with the roles this process is playing when `process.roles` is non-empty. This is required configuration when running in KRaft mode.
  
  |               |           |
  | ------------- | --------- |
  | Type:         | int       |
  | Default:      | -1        |
  | Valid Values: |           |
  | Importance:   | high      |
  | Update Mode:  | read-only |

- #### [num.io.threads](https://kafka.apache.org/documentation/#brokerconfigs_num.io.threads)
  
  The number of threads that the server uses for processing requests, which may include disk I/O
  
  |               |              |
  | ------------- | ------------ |
  | Type:         | int          |
  | Default:      | 8            |
  | Valid Values: | [1,...]      |
  | Importance:   | high         |
  | Update Mode:  | cluster-wide |

- #### [num.network.threads](https://kafka.apache.org/documentation/#brokerconfigs_num.network.threads)
  
  The number of threads that the server uses for receiving requests from the network and sending responses to the network. Noted: each listener (except for controller listener) creates its own thread pool.
  
  |               |              |
  | ------------- | ------------ |
  | Type:         | int          |
  | Default:      | 3            |
  | Valid Values: | [1,...]      |
  | Importance:   | high         |
  | Update Mode:  | cluster-wide |

- #### [num.recovery.threads.per.data.dir](https://kafka.apache.org/documentation/#brokerconfigs_num.recovery.threads.per.data.dir)
  
  The number of threads per data directory to be used for log recovery at startup and flushing at shutdown
  
  |               |              |
  | ------------- | ------------ |
  | Type:         | int          |
  | Default:      | 1            |
  | Valid Values: | [1,...]      |
  | Importance:   | high         |
  | Update Mode:  | cluster-wide |

- #### [num.replica.alter.log.dirs.threads](https://kafka.apache.org/documentation/#brokerconfigs_num.replica.alter.log.dirs.threads)
  
  The number of threads that can move replicas between log directories, which may include disk I/O
  
  |               |           |
  | ------------- | --------- |
  | Type:         | int       |
  | Default:      | null      |
  | Valid Values: |           |
  | Importance:   | high      |
  | Update Mode:  | read-only |

- #### [num.replica.fetchers](https://kafka.apache.org/documentation/#brokerconfigs_num.replica.fetchers)
  
  Number of fetcher threads used to replicate records from each source broker. The total number of fetchers on each broker is bound by `num.replica.fetchers` multiplied by the number of brokers in the cluster.Increasing this value can increase the degree of I/O parallelism in the follower and leader broker at the cost of higher CPU and memory utilization.
  
  |               |              |
  | ------------- | ------------ |
  | Type:         | int          |
  | Default:      | 1            |
  | Valid Values: |              |
  | Importance:   | high         |
  | Update Mode:  | cluster-wide |

- #### [offset.metadata.max.bytes](https://kafka.apache.org/documentation/#brokerconfigs_offset.metadata.max.bytes)
  
  The maximum size for a metadata entry associated with an offset commit.
  
  |               |                    |
  | ------------- | ------------------ |
  | Type:         | int                |
  | Default:      | 4096 (4 kibibytes) |
  | Valid Values: |                    |
  | Importance:   | high               |
  | Update Mode:  | read-only          |

- #### [offsets.commit.required.acks](https://kafka.apache.org/documentation/#brokerconfigs_offsets.commit.required.acks)
  
  DEPRECATED: The required acks before the commit can be accepted. In general, the default (-1) should not be overridden.
  
  |               |           |
  | ------------- | --------- |
  | Type:         | short     |
  | Default:      | -1        |
  | Valid Values: |           |
  | Importance:   | high      |
  | Update Mode:  | read-only |

- #### [offsets.commit.timeout.ms](https://kafka.apache.org/documentation/#brokerconfigs_offsets.commit.timeout.ms)
  
  Offset commit will be delayed until all replicas for the offsets topic receive the commit or this timeout is reached. This is similar to the producer request timeout.
  
  |               |                  |
  | ------------- | ---------------- |
  | Type:         | int              |
  | Default:      | 5000 (5 seconds) |
  | Valid Values: | [1,...]          |
  | Importance:   | high             |
  | Update Mode:  | read-only        |

- #### [offsets.load.buffer.size](https://kafka.apache.org/documentation/#brokerconfigs_offsets.load.buffer.size)
  
  Batch size for reading from the offsets segments when loading offsets into the cache (soft-limit, overridden if records are too large).
  
  |               |           |
  | ------------- | --------- |
  | Type:         | int       |
  | Default:      | 5242880   |
  | Valid Values: | [1,...]   |
  | Importance:   | high      |
  | Update Mode:  | read-only |

- #### [offsets.retention.check.interval.ms](https://kafka.apache.org/documentation/#brokerconfigs_offsets.retention.check.interval.ms)
  
  Frequency at which to check for stale offsets
  
  |               |                     |
  | ------------- | ------------------- |
  | Type:         | long                |
  | Default:      | 600000 (10 minutes) |
  | Valid Values: | [1,...]             |
  | Importance:   | high                |
  | Update Mode:  | read-only           |

- #### [offsets.retention.minutes](https://kafka.apache.org/documentation/#brokerconfigs_offsets.retention.minutes)
  
  For subscribed consumers, committed offset of a specific partition will be expired and discarded when 1) this retention period has elapsed after the consumer group loses all its consumers (i.e. becomes empty); 2) this retention period has elapsed since the last time an offset is committed for the partition and the group is no longer subscribed to the corresponding topic. For standalone consumers (using manual assignment), offsets will be expired after this retention period has elapsed since the time of last commit. Note that when a group is deleted via the delete-group request, its committed offsets will also be deleted without extra retention period; also when a topic is deleted via the delete-topic request, upon propagated metadata update any group's committed offsets for that topic will also be deleted without extra retention period.
  
  |               |           |
  | ------------- | --------- |
  | Type:         | int       |
  | Default:      | 10080     |
  | Valid Values: | [1,...]   |
  | Importance:   | high      |
  | Update Mode:  | read-only |

- #### [offsets.topic.compression.codec](https://kafka.apache.org/documentation/#brokerconfigs_offsets.topic.compression.codec)
  
  Compression codec for the offsets topic - compression may be used to achieve "atomic" commits.
  
  |               |           |
  | ------------- | --------- |
  | Type:         | int       |
  | Default:      | 0         |
  | Valid Values: |           |
  | Importance:   | high      |
  | Update Mode:  | read-only |

- #### [offsets.topic.num.partitions](https://kafka.apache.org/documentation/#brokerconfigs_offsets.topic.num.partitions)
  
  The number of partitions for the offset commit topic (should not change after deployment).
  
  |               |           |
  | ------------- | --------- |
  | Type:         | int       |
  | Default:      | 50        |
  | Valid Values: | [1,...]   |
  | Importance:   | high      |
  | Update Mode:  | read-only |

- #### [offsets.topic.replication.factor](https://kafka.apache.org/documentation/#brokerconfigs_offsets.topic.replication.factor)
  
  The replication factor for the offsets topic (set higher to ensure availability). Internal topic creation will fail until the cluster size meets this replication factor requirement.
  
  |               |           |
  | ------------- | --------- |
  | Type:         | short     |
  | Default:      | 3         |
  | Valid Values: | [1,...]   |
  | Importance:   | high      |
  | Update Mode:  | read-only |

- #### [offsets.topic.segment.bytes](https://kafka.apache.org/documentation/#brokerconfigs_offsets.topic.segment.bytes)
  
  The offsets topic segment bytes should be kept relatively small in order to facilitate faster log compaction and cache loads.
  
  |               |                           |
  | ------------- | ------------------------- |
  | Type:         | int                       |
  | Default:      | 104857600 (100 mebibytes) |
  | Valid Values: | [1,...]                   |
  | Importance:   | high                      |
  | Update Mode:  | read-only                 |

- #### [process.roles](https://kafka.apache.org/documentation/#brokerconfigs_process.roles)
  
  The roles that this process plays: 'broker', 'controller', or 'broker,controller' if it is both. This configuration is only applicable for clusters in KRaft (Kafka Raft) mode (instead of ZooKeeper). Leave this config undefined or empty for ZooKeeper clusters.
  
  |               |                      |
  | ------------- | -------------------- |
  | Type:         | list                 |
  | Default:      | ""                   |
  | Valid Values: | [broker, controller] |
  | Importance:   | high                 |
  | Update Mode:  | read-only            |

- #### [queued.max.requests](https://kafka.apache.org/documentation/#brokerconfigs_queued.max.requests)
  
  The number of queued requests allowed for data-plane, before blocking the network threads
  
  |               |           |
  | ------------- | --------- |
  | Type:         | int       |
  | Default:      | 500       |
  | Valid Values: | [1,...]   |
  | Importance:   | high      |
  | Update Mode:  | read-only |

- #### [replica.fetch.min.bytes](https://kafka.apache.org/documentation/#brokerconfigs_replica.fetch.min.bytes)
  
  Minimum bytes expected for each fetch response. If not enough bytes, wait up to `replica.fetch.wait.max.ms` (broker config).
  
  |               |           |
  | ------------- | --------- |
  | Type:         | int       |
  | Default:      | 1         |
  | Valid Values: |           |
  | Importance:   | high      |
  | Update Mode:  | read-only |

- #### [replica.fetch.wait.max.ms](https://kafka.apache.org/documentation/#brokerconfigs_replica.fetch.wait.max.ms)
  
  The maximum wait time for each fetcher request issued by follower replicas. This value should always be less than the replica.lag.time.max.ms at all times to prevent frequent shrinking of ISR for low throughput topics
  
  |               |           |
  | ------------- | --------- |
  | Type:         | int       |
  | Default:      | 500       |
  | Valid Values: |           |
  | Importance:   | high      |
  | Update Mode:  | read-only |

- #### [replica.high.watermark.checkpoint.interval.ms](https://kafka.apache.org/documentation/#brokerconfigs_replica.high.watermark.checkpoint.interval.ms)
  
  The frequency with which the high watermark is saved out to disk
  
  |               |                  |
  | ------------- | ---------------- |
  | Type:         | long             |
  | Default:      | 5000 (5 seconds) |
  | Valid Values: |                  |
  | Importance:   | high             |
  | Update Mode:  | read-only        |

- #### [replica.lag.time.max.ms](https://kafka.apache.org/documentation/#brokerconfigs_replica.lag.time.max.ms)
  
  If a follower hasn't sent any fetch requests or hasn't consumed up to the leaders log end offset for at least this time, the leader will remove the follower from isr
  
  |               |                    |
  | ------------- | ------------------ |
  | Type:         | long               |
  | Default:      | 30000 (30 seconds) |
  | Valid Values: |                    |
  | Importance:   | high               |
  | Update Mode:  | read-only          |

- #### [replica.socket.receive.buffer.bytes](https://kafka.apache.org/documentation/#brokerconfigs_replica.socket.receive.buffer.bytes)
  
  The socket receive buffer for network requests to the leader for replicating data
  
  |               |                      |
  | ------------- | -------------------- |
  | Type:         | int                  |
  | Default:      | 65536 (64 kibibytes) |
  | Valid Values: |                      |
  | Importance:   | high                 |
  | Update Mode:  | read-only            |

- #### [replica.socket.timeout.ms](https://kafka.apache.org/documentation/#brokerconfigs_replica.socket.timeout.ms)
  
  The socket timeout for network requests. Its value should be at least replica.fetch.wait.max.ms
  
  |               |                    |
  | ------------- | ------------------ |
  | Type:         | int                |
  | Default:      | 30000 (30 seconds) |
  | Valid Values: |                    |
  | Importance:   | high               |
  | Update Mode:  | read-only          |

- #### [request.timeout.ms](https://kafka.apache.org/documentation/#brokerconfigs_request.timeout.ms)
  
  The configuration controls the maximum amount of time the client will wait for the response of a request. If the response is not received before the timeout elapses the client will resend the request if necessary or fail the request if retries are exhausted.
  
  |               |                    |
  | ------------- | ------------------ |
  | Type:         | int                |
  | Default:      | 30000 (30 seconds) |
  | Valid Values: |                    |
  | Importance:   | high               |
  | Update Mode:  | read-only          |

- #### [sasl.mechanism.controller.protocol](https://kafka.apache.org/documentation/#brokerconfigs_sasl.mechanism.controller.protocol)
  
  SASL mechanism used for communication with controllers. Default is GSSAPI.
  
  |               |           |
  | ------------- | --------- |
  | Type:         | string    |
  | Default:      | GSSAPI    |
  | Valid Values: |           |
  | Importance:   | high      |
  | Update Mode:  | read-only |

- #### [socket.receive.buffer.bytes](https://kafka.apache.org/documentation/#brokerconfigs_socket.receive.buffer.bytes)
  
  The SO_RCVBUF buffer of the socket server sockets. If the value is -1, the OS default will be used.
  
  |               |                        |
  | ------------- | ---------------------- |
  | Type:         | int                    |
  | Default:      | 102400 (100 kibibytes) |
  | Valid Values: |                        |
  | Importance:   | high                   |
  | Update Mode:  | read-only              |

- #### [socket.request.max.bytes](https://kafka.apache.org/documentation/#brokerconfigs_socket.request.max.bytes)
  
  The maximum number of bytes in a socket request
  
  |               |                           |
  | ------------- | ------------------------- |
  | Type:         | int                       |
  | Default:      | 104857600 (100 mebibytes) |
  | Valid Values: | [1,...]                   |
  | Importance:   | high                      |
  | Update Mode:  | read-only                 |

- #### [socket.send.buffer.bytes](https://kafka.apache.org/documentation/#brokerconfigs_socket.send.buffer.bytes)
  
  The SO_SNDBUF buffer of the socket server sockets. If the value is -1, the OS default will be used.
  
  |               |                        |
  | ------------- | ---------------------- |
  | Type:         | int                    |
  | Default:      | 102400 (100 kibibytes) |
  | Valid Values: |                        |
  | Importance:   | high                   |
  | Update Mode:  | read-only              |

- #### [transaction.max.timeout.ms](https://kafka.apache.org/documentation/#brokerconfigs_transaction.max.timeout.ms)
  
  The maximum allowed timeout for transactions. If a client’s requested transaction time exceed this, then the broker will return an error in InitProducerIdRequest. This prevents a client from too large of a timeout, which can stall consumers reading from topics included in the transaction.
  
  |               |                     |
  | ------------- | ------------------- |
  | Type:         | int                 |
  | Default:      | 900000 (15 minutes) |
  | Valid Values: | [1,...]             |
  | Importance:   | high                |
  | Update Mode:  | read-only           |

- #### [transaction.state.log.load.buffer.size](https://kafka.apache.org/documentation/#brokerconfigs_transaction.state.log.load.buffer.size)
  
  Batch size for reading from the transaction log segments when loading producer ids and transactions into the cache (soft-limit, overridden if records are too large).
  
  |               |           |
  | ------------- | --------- |
  | Type:         | int       |
  | Default:      | 5242880   |
  | Valid Values: | [1,...]   |
  | Importance:   | high      |
  | Update Mode:  | read-only |

- #### [transaction.state.log.min.isr](https://kafka.apache.org/documentation/#brokerconfigs_transaction.state.log.min.isr)
  
  The minimum number of replicas that must acknowledge a write to transaction topic in order to be considered successful.
  
  |               |           |
  | ------------- | --------- |
  | Type:         | int       |
  | Default:      | 2         |
  | Valid Values: | [1,...]   |
  | Importance:   | high      |
  | Update Mode:  | read-only |

- #### [transaction.state.log.num.partitions](https://kafka.apache.org/documentation/#brokerconfigs_transaction.state.log.num.partitions)
  
  The number of partitions for the transaction topic (should not change after deployment).
  
  |               |           |
  | ------------- | --------- |
  | Type:         | int       |
  | Default:      | 50        |
  | Valid Values: | [1,...]   |
  | Importance:   | high      |
  | Update Mode:  | read-only |

- #### [transaction.state.log.replication.factor](https://kafka.apache.org/documentation/#brokerconfigs_transaction.state.log.replication.factor)
  
  The replication factor for the transaction topic (set higher to ensure availability). Internal topic creation will fail until the cluster size meets this replication factor requirement.
  
  |               |           |
  | ------------- | --------- |
  | Type:         | short     |
  | Default:      | 3         |
  | Valid Values: | [1,...]   |
  | Importance:   | high      |
  | Update Mode:  | read-only |

- #### [transaction.state.log.segment.bytes](https://kafka.apache.org/documentation/#brokerconfigs_transaction.state.log.segment.bytes)
  
  The transaction topic segment bytes should be kept relatively small in order to facilitate faster log compaction and cache loads
  
  |               |                           |
  | ------------- | ------------------------- |
  | Type:         | int                       |
  | Default:      | 104857600 (100 mebibytes) |
  | Valid Values: | [1,...]                   |
  | Importance:   | high                      |
  | Update Mode:  | read-only                 |

- #### [transactional.id.expiration.ms](https://kafka.apache.org/documentation/#brokerconfigs_transactional.id.expiration.ms)
  
  The time in ms that the transaction coordinator will wait without receiving any transaction status updates for the current transaction before expiring its transactional id. Transactional IDs will not expire while a the transaction is still ongoing.
  
  |               |                    |
  | ------------- | ------------------ |
  | Type:         | int                |
  | Default:      | 604800000 (7 days) |
  | Valid Values: | [1,...]            |
  | Importance:   | high               |
  | Update Mode:  | read-only          |

- #### [unclean.leader.election.enable](https://kafka.apache.org/documentation/#brokerconfigs_unclean.leader.election.enable)
  
  Indicates whether to enable replicas not in the ISR set to be elected as leader as a last resort, even though doing so may result in data loss
  
  Note: In KRaft mode, when enabling this config dynamically, it needs to wait for the unclean leader election thread to trigger election periodically (default is 5 minutes). Please run `kafka-leader-election.sh` with `unclean` option to trigger the unclean leader election immediately if needed.
  
  |               |              |
  | ------------- | ------------ |
  | Type:         | boolean      |
  | Default:      | false        |
  | Valid Values: |              |
  | Importance:   | high         |
  | Update Mode:  | cluster-wide |

- #### [zookeeper.connect](https://kafka.apache.org/documentation/#brokerconfigs_zookeeper.connect)
  
  Specifies the ZooKeeper connection string in the form `hostname:port` where host and port are the host and port of a ZooKeeper server. To allow connecting through other ZooKeeper nodes when that ZooKeeper machine is down you can also specify multiple hosts in the form `hostname1:port1,hostname2:port2,hostname3:port3`.  
  The server can also have a ZooKeeper chroot path as part of its ZooKeeper connection string which puts its data under some path in the global ZooKeeper namespace. For example to give a chroot path of `/chroot/path` you would give the connection string as `hostname1:port1,hostname2:port2,hostname3:port3/chroot/path`.
  
  |               |           |
  | ------------- | --------- |
  | Type:         | string    |
  | Default:      | null      |
  | Valid Values: |           |
  | Importance:   | high      |
  | Update Mode:  | read-only |

- #### [zookeeper.connection.timeout.ms](https://kafka.apache.org/documentation/#brokerconfigs_zookeeper.connection.timeout.ms)
  
  The max time that the client waits to establish a connection to ZooKeeper. If not set, the value in zookeeper.session.timeout.ms is used
  
  |               |           |
  | ------------- | --------- |
  | Type:         | int       |
  | Default:      | null      |
  | Valid Values: |           |
  | Importance:   | high      |
  | Update Mode:  | read-only |

- #### [zookeeper.max.in.flight.requests](https://kafka.apache.org/documentation/#brokerconfigs_zookeeper.max.in.flight.requests)
  
  The maximum number of unacknowledged requests the client will send to ZooKeeper before blocking.
  
  |               |           |
  | ------------- | --------- |
  | Type:         | int       |
  | Default:      | 10        |
  | Valid Values: | [1,...]   |
  | Importance:   | high      |
  | Update Mode:  | read-only |

- #### [zookeeper.metadata.migration.enable](https://kafka.apache.org/documentation/#brokerconfigs_zookeeper.metadata.migration.enable)
  
  Enable ZK to KRaft migration
  
  |               |           |
  | ------------- | --------- |
  | Type:         | boolean   |
  | Default:      | false     |
  | Valid Values: |           |
  | Importance:   | high      |
  | Update Mode:  | read-only |

- #### [zookeeper.session.timeout.ms](https://kafka.apache.org/documentation/#brokerconfigs_zookeeper.session.timeout.ms)
  
  Zookeeper session timeout
  
  |               |                    |
  | ------------- | ------------------ |
  | Type:         | int                |
  | Default:      | 18000 (18 seconds) |
  | Valid Values: |                    |
  | Importance:   | high               |
  | Update Mode:  | read-only          |

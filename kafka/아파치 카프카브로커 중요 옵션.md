### [3.1 Broker Configs](https://kafka.apache.org/documentation/#brokerconfigs)

The essential configurations are the following:

- `broker.id`
- `log.dirs`
- `zookeeper.connect`
  - `카프카와 주키퍼를 연결할 포트`
  - `zookeeper.connect=zoo1:2181,zoo2:2181,zoo3:2181`

Topic-level configurations and defaults are discussed in more detail [below](https://kafka.apache.org/documentation/#topicconfigs).

- #### [advertised.listeners](https://kafka.apache.org/documentation/#brokerconfigs_advertised.listeners)
  
  - 클라이언트가 사용할 리스너 정보
  
  - `advertised.listeners=INSIDE://broker1.internal:9093,OUTSIDE://broker1.example.com:9094`
  
  - 0.0.0.0 불가
  
  - 기본값 null
  
  |               |            |
  | ------------- | ---------- |
  | Type:         | string     |
  | Default:      | null       |
  | Valid Values: |            |
  | Importance:   | high       |
  | Update Mode:  | per-broker |

- #### [auto.create.topics.enable](https://kafka.apache.org/documentation/#brokerconfigs_auto.create.topics.enable)
  
  등록되지 않은 토픽 생성
  
  |               |           |
  | ------------- | --------- |
  | Type:         | boolean   |
  | Default:      | true      |
  | Valid Values: |           |
  | Importance:   | high      |
  | Update Mode:  | read-only |

- #### [auto.leader.rebalance.enable](https://kafka.apache.org/documentation/#brokerconfigs_auto.leader.rebalance.enable)
  
  카프카 센티넬 옵션
  
  리더 컨디션 파악후 다른 레플리카를 리더로
  
  |               |           |
  | ------------- | --------- |
  | Type:         | boolean   |
  | Default:      | true      |
  | Valid Values: |           |
  | Importance:   | high      |
  | Update Mode:  | read-only |

- #### [background.threads](https://kafka.apache.org/documentation/#brokerconfigs_background.threads)
  
  The number of threads to use for various background processing tasks
  
  |               |              |
  | ------------- | ------------ |
  | Type:         | int          |
  | Default:      | 10           |
  | Valid Values: | [1,...]      |
  | Importance:   | high         |
  | Update Mode:  | cluster-wide |

- #### [broker.id](https://kafka.apache.org/documentation/#brokerconfigs_broker.id)
  
  `broker.id`는 Kafka 클러스터 내 각 브로커를 **고유하게 식별하는 ID**입니다. 이 값이 설정되지 않으면 Kafka가 자동으로 고유한 `broker.id`를 생성합니다. 다만, ZooKeeper와 충돌을 피하기 위해 자동 생성된 `broker.id`는 `reserved.broker.max.id + 1`부터 시작합니다.
  
  |               |           |
  | ------------- | --------- |
  | Type:         | int       |
  | Default:      | -1        |
  | Valid Values: |           |
  | Importance:   | high      |
  | Update Mode:  | read-only |

- #### [compression.type](https://kafka.apache.org/documentation/#brokerconfigs_compression.type)
  
  압축 형식은 `gzip`, `snappy`, `lz4`, `zstd` 등과 같은 표준 압축 코덱을 사용할 수 있습니다. `uncompressed`를 사용하면 압축을 사용하지 않게 되며, `producer`를 설정하면 **프로듀서가 설정한 압축 방식**을 그대로 사용합니다.
  
  압축을 사용하면 디스크 사용량을 줄이고 네트워크 성능을 향상시킬 수 있지만, CPU 사용량이 늘어날 수 있습니다.
  
  `compression.type=gzip  # gzip 압축 사용`
  
  |               |                                                   |
  | ------------- | ------------------------------------------------- |
  | Type:         | string                                            |
  | Default:      | producer                                          |
  | Valid Values: | [uncompressed, zstd, lz4, snappy, gzip, producer] |
  | Importance:   | high                                              |
  | Update Mode:  | cluster-wide                                      |

- #### [control.plane.listener.name](https://kafka.apache.org/documentation/#brokerconfigs_control.plane.listener.name)  
  
  컨트롤러와 브로커 간 통신에 사용되는 리스너 이름입니다. 브로커는 control.plane.listener.name을 사용하여 리스너 목록에서 해당 엔드포인트를 찾아 컨트롤러의 연결 요청을 대기합니다. 예를 들어, 브로커의 설정이 아래와 같다면:
  `listeners = INTERNAL://192.1.1.8:9092, EXTERNAL://10.1.1.5:9093, CONTROLLER://192.1.1.8:9094listener.security.protocol.map = INTERNAL:PLAINTEXT, EXTERNAL:SSL, CONTROLLER:SSLcontrol.plane.listener.name = CONTROLLER`  
  브로커는 시작 시 192.1.1.8:9094에서 SSL 보안 프로토콜로 연결 대기를 시작합니다.
  컨트롤러는 ZooKeeper를 통해 브로커의 공개 엔드포인트를 발견한 뒤, control.plane.listener.name을 사용해 해당 브로커와 연결을 설정합니다.
  
  예를 들어, ZooKeeper에 공개된 브로커 엔드포인트가 아래와 같다면:
  `"endpoints" : ["INTERNAL://broker1.example.com:9092","EXTERNAL://broker1.example.com:9093","CONTROLLER://broker1.example.com:9094"]`  
  컨트롤러의 설정이 다음과 같을 경우:
  `listener.security.protocol.map = INTERNAL:PLAINTEXT, EXTERNAL:SSL, CONTROLLER:SSLcontrol.plane.listener.name = CONTROLLER`  
  컨트롤러는 broker1.example.com:9094에서 SSL을 사용해 브로커와 연결합니다.
  만약 명시적으로 설정되지 않았다면 기본값은 null이며, 컨트롤러 전용 엔드포인트는 생성되지 않습니다.
  명시적으로 설정할 경우, inter.broker.listener.name 값과 동일할 수 없습니다.
  
  |               |           |
  | ------------- | --------- |
  | Type:         | string    |
  | Default:      | null      |
  | Valid Values: |           |
  | Importance:   | high      |
  | Update Mode:  | read-only |

- #### [controller.listener.names](https://kafka.apache.org/documentation/#brokerconfigs_controller.listener.names)
  
  컨트롤러가 사용하는 리스너 이름의 목록입니다. 이는 KRaft 모드에서 반드시 설정해야 하며, 컨트롤러 쿼럼과 통신할 때 항상 이 목록의 첫 번째 리스너를 사용합니다.
  주의: ZooKeeper 기반 컨트롤러에서는 이 설정을 사용하지 마십시오.
  
  |               |           |
  | ------------- | --------- |
  | Type:         | string    |
  | Default:      | null      |
  | Valid Values: |           |
  | Importance:   | high      |
  | Update Mode:  | read-only |

- #### [controller.quorum.bootstrap.servers](https://kafka.apache.org/documentation/#brokerconfigs_controller.quorum.bootstrap.servers)
  
  클러스터 메타데이터를 부트스트랩하기 위해 사용하는 엔드포인트의 목록입니다. 엔드포인트는 {host}:{port} 형식의 콤마로 구분된 목록으로 지정합니다. 예: `localhost:9092,localhost:9093,localhost:9094`.
  
  |               |                |
  | ------------- | -------------- |
  | Type:         | list           |
  | Default:      | ""             |
  | Valid Values: | non-empty list |
  | Importance:   | high           |
  | Update Mode:  | read-only      |

- #### [controller.quorum.election.backoff.max.ms](https://kafka.apache.org/documentation/#brokerconfigs_controller.quorum.election.backoff.max.ms)
  
  새로운 선거를 시작하기 전에 최대 대기 시간(밀리초 단위)을 설정합니다. 이 값은 이진 지수적 백오프 메커니즘에서 사용되며, 선거의 교착 상태를 방지하는 데 도움을 줍니다.
  
  |               |                 |
  | ------------- | --------------- |
  | Type:         | int             |
  | Default:      | 1000 (1 second) |
  | Valid Values: |                 |
  | Importance:   | high            |
  | Update Mode:  | read-only       |

- #### [controller.quorum.election.timeout.ms](https://kafka.apache.org/documentation/#brokerconfigs_controller.quorum.election.timeout.ms)
  
  리더로부터 데이터를 가져오지 못한 상태에서 새로운 선거를 시작하기 전까지 최대 대기 시간(밀리초 단위)을 설정합니다.
  
  |               |                 |
  | ------------- | --------------- |
  | Type:         | int             |
  | Default:      | 1000 (1 second) |
  | Valid Values: |                 |
  | Importance:   | high            |
  | Update Mode:  | read-only       |

- #### [controller.quorum.fetch.timeout.ms](https://kafka.apache.org/documentation/#brokerconfigs_controller.quorum.fetch.timeout.ms)
  
  선거권자(voter)가 현재 리더로부터 데이터를 성공적으로 가져오지 못했을 때, 후보로 전환하고 선거를 시작하기 전까지의 최대 대기 시간(밀리초 단위)을 정의합니다.
  리더는 과반수의 쿼럼으로부터 fetch 또는 fetchSnapshot 요청을 유효하게 받지 못하면 리더 자격을 포기합니다.
  
  |               |                  |
  | ------------- | ---------------- |
  | Type:         | int              |
  | Default:      | 2000 (2 seconds) |
  | Valid Values: |                  |
  | Importance:   | high             |
  | Update Mode:  | read-only        |

- #### [controller.quorum.voters](https://kafka.apache.org/documentation/#brokerconfigs_controller.quorum.voters)
  
  선거권자 집합의 ID/엔드포인트 정보를 지정합니다. {id}@{host}:{port} 형식의 엔트리로 콤마로 구분된 목록입니다.
  
  |               |                |
  | ------------- | -------------- |
  | Type:         | list           |
  | Default:      | ""             |
  | Valid Values: | non-empty list |
  | Importance:   | high           |
  | Update Mode:  | read-only      |

- #### [delete.topic.enable](https://kafka.apache.org/documentation/#brokerconfigs_delete.topic.enable)
  
  토픽 삭제를 활성화합니다. 이 설정이 비활성화된 경우, 관리 도구를 통해 실행되는 토픽 삭제 요청은 아무런 효과도 없습니다.
  
  |               |           |
  | ------------- | --------- |
  | Type:         | boolean   |
  | Default:      | true      |
  | Valid Values: |           |
  | Importance:   | high      |
  | Update Mode:  | read-only |

- #### [early.start.listeners](https://kafka.apache.org/documentation/#brokerconfigs_early.start.listeners)
  
  권한 부여자(authorizer)가 초기화되기 전에 시작될 수 있는 리스너의 이름 목록을 설정합니다.
  이는 권한 부여자가 클러스터 자체에 의존하여 부트스트래핑해야 하는 경우(예: 메타데이터 로그에 ACL을 저장하는 StandardAuthorizer)에 유용합니다.
  기본적으로, controller.listener.names에 포함된 모든 리스너는 자동으로 "early start listeners"로 간주됩니다.
  외부 트래픽을 수신하는 리스너는 이 목록에 포함하지 말아야 합니다.
  
  |               |           |
  | ------------- | --------- |
  | Type:         | string    |
  | Default:      | null      |
  | Valid Values: |           |
  | Importance:   | high      |
  | Update Mode:  | read-only |

- #### [eligible.leader.replicas.enable](https://kafka.apache.org/documentation/#brokerconfigs_eligible.leader.replicas.enable)
  
  리더로 적합한 **복제본(eligible leader replicas)**의 활성화를 제어합니다.
  
  |               |           |
  | ------------- | --------- |
  | Type:         | boolean   |
  | Default:      | false     |
  | Valid Values: |           |
  | Importance:   | high      |
  | Update Mode:  | read-only |

- #### [leader.imbalance.check.interval.seconds](https://kafka.apache.org/documentation/#brokerconfigs_leader.imbalance.check.interval.seconds)
  
  컨트롤러가 파티션 리더 불균형을 감지하고 재조정을 트리거하는 주기를 초 단위로 설정합니다.
  
  |               |           |
  | ------------- | --------- |
  | Type:         | long      |
  | Default:      | 300       |
  | Valid Values: | [1,...]   |
  | Importance:   | high      |
  | Update Mode:  | read-only |

- #### [leader.imbalance.per.broker.percentage](https://kafka.apache.org/documentation/#brokerconfigs_leader.imbalance.per.broker.percentage)
  
  각 브로커에서 허용되는 리더 불균형의 비율(백분율)을 설정합니다.
  컨트롤러는 이 값이 초과되면 리더 균형 작업을 실행합니다.
  
  |               |           |
  | ------------- | --------- |
  | Type:         | int       |
  | Default:      | 10        |
  | Valid Values: |           |
  | Importance:   | high      |
  | Update Mode:  | read-only |

- #### [listeners](https://kafka.apache.org/documentation/#brokerconfigs_listeners)
  
  Kafka 브로커가 수신할 리스너의 URI와 이름을 설정합니다.
  콤마로 구분된 리스트 형식으로 구성되며, 리스너 이름이 보안 프로토콜이 아닌 경우에는 반드시 listener.security.protocol.map도 설정해야 합니다.

  포트 및 이름 규칙: 리스너 이름과 포트 번호는 고유해야 하지만, 하나의 리스너가 IPv4, 다른 리스너가 같은 포트에서 IPv6를 사용하는 경우는 예외입니다.
  호스트 바인딩:
  0.0.0.0: 모든 네트워크 인터페이스에 바인딩.
  빈 값: 기본 인터페이스에 바인딩.
  `PLAINTEXT://myhost:9092,SSL://:9091`
  `CLIENT://0.0.0.0:9092,REPLICATION://localhost:9093`
  `PLAINTEXT://127.0.0.1:9092,SSL://[::1]:9092`

  |               |                   |
  | ------------- | ----------------- |
  | Type:         | string            |
  | Default:      | PLAINTEXT://:9092 |
  | Valid Values: |                   |
  | Importance:   | high              |
  | Update Mode:  | per-broker        |

- #### [log.dir](https://kafka.apache.org/documentation/#brokerconfigs_log.dir)
  
  설명: 로그 데이터(토픽 메시지)가 저장되는 기본 디렉토리입니다.
  
  |               |                 |
  | ------------- | --------------- |
  | Type:         | string          |
  | Default:      | /tmp/kafka-logs |
  | Valid Values: |                 |
  | Importance:   | high            |
  | Update Mode:  | read-only       |

- #### [log.dirs](https://kafka.apache.org/documentation/#brokerconfigs_log.dirs)
  
  로그 데이터가 저장될 여러 디렉토리를 쉼표로 구분하여 설정할 수 있습니다. 설정하지 않으면 log.dir 값을 사용합니다.
  
  |               |           |
  | ------------- | --------- |
  | Type:         | string    |
  | Default:      | null      |
  | Valid Values: |           |
  | Importance:   | high      |
  | Update Mode:  | read-only |

- #### [log.flush.interval.messages](https://kafka.apache.org/documentation/#brokerconfigs_log.flush.interval.messages)
  
  로그 파티션에 특정 개수의 메시지가 누적된 후 디스크로 플러시하는 기준 메시지 수를 설정합니다.
  
  |               |                     |
  | ------------- | ------------------- |
  | Type:         | long                |
  | Default:      | 9223372036854775807 |
  | Valid Values: | [1,...]             |
  | Importance:   | high                |
  | Update Mode:  | cluster-wide        |

- #### [log.flush.interval.ms](https://kafka.apache.org/documentation/#brokerconfigs_log.flush.interval.ms)
  
  메모리에 남아 있는 메시지가 디스크로 플러시되기 전 최대 시간을 밀리초 단위로 설정합니다. 설정하지 않으면 log.flush.scheduler.interval.ms 값이 사용됩니다.
  
  |               |              |
  | ------------- | ------------ |
  | Type:         | long         |
  | Default:      | null         |
  | Valid Values: |              |
  | Importance:   | high         |
  | Update Mode:  | cluster-wide |

- #### [log.flush.offset.checkpoint.interval.ms](https://kafka.apache.org/documentation/#brokerconfigs_log.flush.offset.checkpoint.interval.ms)
  
  마지막 플러시 오프셋 정보를 디스크에 기록하는 주기를 밀리초 단위로 설정합니다. 이 기록은 로그 복구 지점으로 사용됩니다.
  
  |               |                  |
  | ------------- | ---------------- |
  | Type:         | int              |
  | Default:      | 60000 (1 minute) |
  | Valid Values: | [0,...]          |
  | Importance:   | high             |
  | Update Mode:  | read-only        |

- #### [log.flush.scheduler.interval.ms](https://kafka.apache.org/documentation/#brokerconfigs_log.flush.scheduler.interval.ms)
  
  로그 플러셔가 로그를 디스크로 플러시해야 하는지 확인하는 주기를 밀리초 단위로 설정합니다.
  
  |               |                     |
  | ------------- | ------------------- |
  | Type:         | long                |
  | Default:      | 9223372036854775807 |
  | Valid Values: |                     |
  | Importance:   | high                |
  | Update Mode:  | read-only           |

- #### [log.flush.start.offset.checkpoint.interval.ms](https://kafka.apache.org/documentation/#brokerconfigs_log.flush.start.offset.checkpoint.interval.ms)
  
  로그 시작 오프셋 정보를 디스크에 기록하는 주기를 밀리초 단위로 설정합니다.
  
  |               |                  |
  | ------------- | ---------------- |
  | Type:         | int              |
  | Default:      | 60000 (1 minute) |
  | Valid Values: | [0,...]          |
  | Importance:   | high             |
  | Update Mode:  | read-only        |

- #### [log.retention.bytes](https://kafka.apache.org/documentation/#brokerconfigs_log.retention.bytes)
  
  로그 파일의 최대 크기를 설정하며, 이를 초과하면 로그가 삭제됩니다.
  
  |               |              |
  | ------------- | ------------ |
  | Type:         | long         |
  | Default:      | -1           |
  | Valid Values: |              |
  | Importance:   | high         |
  | Update Mode:  | cluster-wide |

- #### [log.retention.hours](https://kafka.apache.org/documentation/#brokerconfigs_log.retention.hours)
  
  로그 파일을 삭제하기 전 유지할 시간을 시간 단위로 설정합니다. log.retention.ms보다 우선순위가 낮습니다.
  
  |               |           |
  | ------------- | --------- |
  | Type:         | int       |
  | Default:      | 168       |
  | Valid Values: |           |
  | Importance:   | high      |
  | Update Mode:  | read-only |

- #### [log.retention.minutes](https://kafka.apache.org/documentation/#brokerconfigs_log.retention.minutes)
  
  로그 파일을 삭제하기 전 유지할 시간을 분 단위로 설정합니다. log.retention.ms보다 우선순위가 낮고, 설정되지 않으면 log.retention.hours 값이 사용됩니다.
  
  |               |           |
  | ------------- | --------- |
  | Type:         | int       |
  | Default:      | null      |
  | Valid Values: |           |
  | Importance:   | high      |
  | Update Mode:  | read-only |

- #### [log.retention.ms](https://kafka.apache.org/documentation/#brokerconfigs_log.retention.ms)
  
  The number of milliseconds to keep a log file before deleting it (in milliseconds), If not set, the value in log.retention.minutes is used. If set to -1, no time limit is applied.
  
  |               |              |
  | ------------- | ------------ |
  | Type:         | long         |
  | Default:      | null         |
  | Valid Values: |              |
  | Importance:   | high         |
  | Update Mode:  | cluster-wide |

- #### [log.roll.hours](https://kafka.apache.org/documentation/#brokerconfigs_log.roll.hours)
  
  새 로그 세그먼트로 롤링되기 전 최대 시간을 시간 단위로 설정합니다. log.roll.ms보다 우선순위가 낮습니다.
  
  |               |           |
  | ------------- | --------- |
  | Type:         | int       |
  | Default:      | 168       |
  | Valid Values: | [1,...]   |
  | Importance:   | high      |
  | Update Mode:  | read-only |

- #### [log.roll.jitter.hours](https://kafka.apache.org/documentation/#brokerconfigs_log.roll.jitter.hours)
  
  로그 롤링 시간(log.roll.hours)에서 랜덤하게 뺄 수 있는 최대 시간을 시간 단위로 설정합니다. log.roll.jitter.ms보다 우선순위가 낮습니다.
  
  |               |           |
  | ------------- | --------- |
  | Type:         | int       |
  | Default:      | 0         |
  | Valid Values: | [0,...]   |
  | Importance:   | high      |
  | Update Mode:  | read-only |

- #### [log.roll.jitter.ms](https://kafka.apache.org/documentation/#brokerconfigs_log.roll.jitter.ms)
  
  The maximum jitter to subtract from logRollTimeMillis (in milliseconds). If not set, the value in log.roll.jitter.hours is used
  
  |               |              |
  | ------------- | ------------ |
  | Type:         | long         |
  | Default:      | null         |
  | Valid Values: |              |
  | Importance:   | high         |
  | Update Mode:  | cluster-wide |

- #### [log.roll.ms](https://kafka.apache.org/documentation/#brokerconfigs_log.roll.ms)
  
  설명: 새 로그 세그먼트로 롤링되기 전 최대 시간을 밀리초 단위로 설정합니다. 설정되지 않으면 log.roll.hours 값이 사용됩니다.
  
  |               |              |
  | ------------- | ------------ |
  | Type:         | long         |
  | Default:      | null         |
  | Valid Values: |              |
  | Importance:   | high         |
  | Update Mode:  | cluster-wide |

- #### [log.segment.bytes](https://kafka.apache.org/documentation/#brokerconfigs_log.segment.bytes)
  
  하나의 로그 파일의 최대 크기
  
  |               |                         |
  | ------------- | ----------------------- |
  | Type:         | int                     |
  | Default:      | 1073741824 (1 gibibyte) |
  | Valid Values: | [14,...]                |
  | Importance:   | high                    |
  | Update Mode:  | cluster-wide            |

- #### [log.segment.delete.delay.ms](https://kafka.apache.org/documentation/#brokerconfigs_log.segment.delete.delay.ms)
  
  로그 파일을 삭제하기 전에 대기하는 시간(밀리초)입니다. 값이 0이면 삭제 대기 시간이 1밀리초로 설정됩니다. 너무 낮은 값은 자주 대기 상태에 들어가게 되어 시스템 성능에 영향을 미칠 수 있습니다.
  
  |               |                  |
  | ------------- | ---------------- |
  | Type:         | long             |
  | Default:      | 60000 (1 minute) |
  | Valid Values: | [0,...]          |
  | Importance:   | high             |
  | Update Mode:  | cluster-wide     |

- #### [message.max.bytes](https://kafka.apache.org/documentation/#brokerconfigs_message.max.bytes)
  
  Kafka에서 허용하는 가장 큰 레코드 배치 크기입니다. 이 값은 압축이 활성화된 경우 압축된 레코드의 크기를 기준으로 적용됩니다. 만약 이 값을 증가시키고, Kafka 0.10.2 이전 버전의 소비자가 있다면, 해당 소비자의 fetch size도 함께 증가시켜야 합니다. 최신 메시지 포맷에서는 모든 레코드가 효율성을 위해 배치로 묶여 저장됩니다. 이전 메시지 포맷에서는 압축되지 않은 레코드가 배치로 묶이지 않으며, 이 제한은 개별 레코드에만 적용됩니다.

  또한, 이 값은 주제별로 `max.message.bytes` 설정을 통해 개별 토픽에서 별도로 설정할 수 있습니다.
  
  |               |              |
  | ------------- | ------------ |
  | Type:         | int          |
  | Default:      | 1048588      |
  | Valid Values: | [0,...]      |
  | Importance:   | high         |
  | Update Mode:  | cluster-wide |

- #### [metadata.log.dir](https://kafka.apache.org/documentation/#brokerconfigs_metadata.log.dir)
  
   KRaft 모드에서 클러스터 메타데이터 로그를 저장할 디렉토리를 설정하는 항목입니다. 설정하지 않으면 log.dirs에서 첫 번째 디렉토리에 메타데이터 로그가 저장됩니다.
  
  |               |           |
  | ------------- | --------- |
  | Type:         | string    |
  | Default:      | null      |
  | Valid Values: |           |
  | Importance:   | high      |
  | Update Mode:  | read-only |

- #### [metadata.log.max.record.bytes.between.snapshots](https://kafka.apache.org/documentation/#brokerconfigs_metadata.log.max.record.bytes.between.snapshots)
  
  This is the maximum number of bytes in the log between the latest snapshot and the high-watermark needed before generating a new snapshot. The default value is 20971520. To generate snapshots based on the time elapsed, see the `metadata.log.max.snapshot.interval.ms` configuration. The Kafka node will generate a snapshot when either the maximum time interval is reached or the maximum bytes limit is reached.
  
  |               |           |
  | ------------- | --------- |
  | Type:         | long      |
  | Default:      | 20971520  |
  | Valid Values: | [1,...]   |
  | Importance:   | high      |
  | Update Mode:  | read-only |

- #### [metadata.log.max.snapshot.interval.ms](https://kafka.apache.org/documentation/#brokerconfigs_metadata.log.max.snapshot.interval.ms)
  
  This is the maximum number of milliseconds to wait to generate a snapshot if there are committed records in the log that are not included in the latest snapshot. A value of zero disables time based snapshot generation. The default value is 3600000. To generate snapshots based on the number of metadata bytes, see the `metadata.log.max.record.bytes.between.snapshots` configuration. The Kafka node will generate a snapshot when either the maximum time interval is reached or the maximum bytes limit is reached.
  
  |               |                  |
  | ------------- | ---------------- |
  | Type:         | long             |
  | Default:      | 3600000 (1 hour) |
  | Valid Values: | [0,...]          |
  | Importance:   | high             |
  | Update Mode:  | read-only        |

- #### [metadata.log.segment.bytes](https://kafka.apache.org/documentation/#brokerconfigs_metadata.log.segment.bytes)
  
  The maximum size of a single metadata log file.
  
  |               |                         |
  | ------------- | ----------------------- |
  | Type:         | int                     |
  | Default:      | 1073741824 (1 gibibyte) |
  | Valid Values: | [12,...]                |
  | Importance:   | high                    |
  | Update Mode:  | read-only               |

- #### [metadata.log.segment.ms](https://kafka.apache.org/documentation/#brokerconfigs_metadata.log.segment.ms)
  
  The maximum time before a new metadata log file is rolled out (in milliseconds).
  
  |               |                    |
  | ------------- | ------------------ |
  | Type:         | long               |
  | Default:      | 604800000 (7 days) |
  | Valid Values: |                    |
  | Importance:   | high               |
  | Update Mode:  | read-only          |

- #### [metadata.max.retention.bytes](https://kafka.apache.org/documentation/#brokerconfigs_metadata.max.retention.bytes)
  
  The maximum combined size of the metadata log and snapshots before deleting old snapshots and log files. Since at least one snapshot must exist before any logs can be deleted, this is a soft limit.
  
  |               |                           |
  | ------------- | ------------------------- |
  | Type:         | long                      |
  | Default:      | 104857600 (100 mebibytes) |
  | Valid Values: |                           |
  | Importance:   | high                      |
  | Update Mode:  | read-only                 |

- #### [metadata.max.retention.ms](https://kafka.apache.org/documentation/#brokerconfigs_metadata.max.retention.ms)
  
  The number of milliseconds to keep a metadata log file or snapshot before deleting it. Since at least one snapshot must exist before any logs can be deleted, this is a soft limit.
  
  |               |                    |
  | ------------- | ------------------ |
  | Type:         | long               |
  | Default:      | 604800000 (7 days) |
  | Valid Values: |                    |
  | Importance:   | high               |
  | Update Mode:  | read-only          |

- #### [min.insync.replicas](https://kafka.apache.org/documentation/#brokerconfigs_min.insync.replicas)
  
  When a producer sets acks to "all" (or "-1"), `min.insync.replicas` specifies the minimum number of replicas that must acknowledge a write for the write to be considered successful. If this minimum cannot be met, then the producer will raise an exception (either `NotEnoughReplicas` or `NotEnoughReplicasAfterAppend`).  
  When used together, `min.insync.replicas` and acks allow you to enforce greater durability guarantees. A typical scenario would be to create a topic with a replication factor of 3, set `min.insync.replicas` to 2, and produce with acks of "all". This will ensure that the producer raises an exception if a majority of replicas do not receive a write.
  
  |               |              |
  | ------------- | ------------ |
  | Type:         | int          |
  | Default:      | 1            |
  | Valid Values: | [1,...]      |
  | Importance:   | high         |
  | Update Mode:  | cluster-wide |

- #### [node.id](https://kafka.apache.org/documentation/#brokerconfigs_node.id)
  
  The node ID associated with the roles this process is playing when `process.roles` is non-empty. This is required configuration when running in KRaft mode.
  
  |               |           |
  | ------------- | --------- |
  | Type:         | int       |
  | Default:      | -1        |
  | Valid Values: |           |
  | Importance:   | high      |
  | Update Mode:  | read-only |

- #### [num.io.threads](https://kafka.apache.org/documentation/#brokerconfigs_num.io.threads)
  
  The number of threads that the server uses for processing requests, which may include disk I/O
  
  |               |              |
  | ------------- | ------------ |
  | Type:         | int          |
  | Default:      | 8            |
  | Valid Values: | [1,...]      |
  | Importance:   | high         |
  | Update Mode:  | cluster-wide |

- #### [num.network.threads](https://kafka.apache.org/documentation/#brokerconfigs_num.network.threads)
  
  The number of threads that the server uses for receiving requests from the network and sending responses to the network. Noted: each listener (except for controller listener) creates its own thread pool.
  
  |               |              |
  | ------------- | ------------ |
  | Type:         | int          |
  | Default:      | 3            |
  | Valid Values: | [1,...]      |
  | Importance:   | high         |
  | Update Mode:  | cluster-wide |

- #### [num.recovery.threads.per.data.dir](https://kafka.apache.org/documentation/#brokerconfigs_num.recovery.threads.per.data.dir)
  
  The number of threads per data directory to be used for log recovery at startup and flushing at shutdown
  
  |               |              |
  | ------------- | ------------ |
  | Type:         | int          |
  | Default:      | 1            |
  | Valid Values: | [1,...]      |
  | Importance:   | high         |
  | Update Mode:  | cluster-wide |

- #### [num.replica.alter.log.dirs.threads](https://kafka.apache.org/documentation/#brokerconfigs_num.replica.alter.log.dirs.threads)
  
  The number of threads that can move replicas between log directories, which may include disk I/O
  
  |               |           |
  | ------------- | --------- |
  | Type:         | int       |
  | Default:      | null      |
  | Valid Values: |           |
  | Importance:   | high      |
  | Update Mode:  | read-only |

- #### [num.replica.fetchers](https://kafka.apache.org/documentation/#brokerconfigs_num.replica.fetchers)
  
  Number of fetcher threads used to replicate records from each source broker. The total number of fetchers on each broker is bound by `num.replica.fetchers` multiplied by the number of brokers in the cluster.Increasing this value can increase the degree of I/O parallelism in the follower and leader broker at the cost of higher CPU and memory utilization.
  
  |               |              |
  | ------------- | ------------ |
  | Type:         | int          |
  | Default:      | 1            |
  | Valid Values: |              |
  | Importance:   | high         |
  | Update Mode:  | cluster-wide |

- #### [offset.metadata.max.bytes](https://kafka.apache.org/documentation/#brokerconfigs_offset.metadata.max.bytes)
  
  The maximum size for a metadata entry associated with an offset commit.
  
  |               |                    |
  | ------------- | ------------------ |
  | Type:         | int                |
  | Default:      | 4096 (4 kibibytes) |
  | Valid Values: |                    |
  | Importance:   | high               |
  | Update Mode:  | read-only          |

- #### [offsets.commit.required.acks](https://kafka.apache.org/documentation/#brokerconfigs_offsets.commit.required.acks)
  
  DEPRECATED: The required acks before the commit can be accepted. In general, the default (-1) should not be overridden.
  
  |               |           |
  | ------------- | --------- |
  | Type:         | short     |
  | Default:      | -1        |
  | Valid Values: |           |
  | Importance:   | high      |
  | Update Mode:  | read-only |

- #### [offsets.commit.timeout.ms](https://kafka.apache.org/documentation/#brokerconfigs_offsets.commit.timeout.ms)
  
  Offset commit will be delayed until all replicas for the offsets topic receive the commit or this timeout is reached. This is similar to the producer request timeout.
  
  |               |                  |
  | ------------- | ---------------- |
  | Type:         | int              |
  | Default:      | 5000 (5 seconds) |
  | Valid Values: | [1,...]          |
  | Importance:   | high             |
  | Update Mode:  | read-only        |

- #### [offsets.load.buffer.size](https://kafka.apache.org/documentation/#brokerconfigs_offsets.load.buffer.size)
  
  Batch size for reading from the offsets segments when loading offsets into the cache (soft-limit, overridden if records are too large).
  
  |               |           |
  | ------------- | --------- |
  | Type:         | int       |
  | Default:      | 5242880   |
  | Valid Values: | [1,...]   |
  | Importance:   | high      |
  | Update Mode:  | read-only |

- #### [offsets.retention.check.interval.ms](https://kafka.apache.org/documentation/#brokerconfigs_offsets.retention.check.interval.ms)
  
  Frequency at which to check for stale offsets
  
  |               |                     |
  | ------------- | ------------------- |
  | Type:         | long                |
  | Default:      | 600000 (10 minutes) |
  | Valid Values: | [1,...]             |
  | Importance:   | high                |
  | Update Mode:  | read-only           |

- #### [offsets.retention.minutes](https://kafka.apache.org/documentation/#brokerconfigs_offsets.retention.minutes)
  
  For subscribed consumers, committed offset of a specific partition will be expired and discarded when 1) this retention period has elapsed after the consumer group loses all its consumers (i.e. becomes empty); 2) this retention period has elapsed since the last time an offset is committed for the partition and the group is no longer subscribed to the corresponding topic. For standalone consumers (using manual assignment), offsets will be expired after this retention period has elapsed since the time of last commit. Note that when a group is deleted via the delete-group request, its committed offsets will also be deleted without extra retention period; also when a topic is deleted via the delete-topic request, upon propagated metadata update any group's committed offsets for that topic will also be deleted without extra retention period.
  
  |               |           |
  | ------------- | --------- |
  | Type:         | int       |
  | Default:      | 10080     |
  | Valid Values: | [1,...]   |
  | Importance:   | high      |
  | Update Mode:  | read-only |

- #### [offsets.topic.compression.codec](https://kafka.apache.org/documentation/#brokerconfigs_offsets.topic.compression.codec)
  
  Compression codec for the offsets topic - compression may be used to achieve "atomic" commits.
  
  |               |           |
  | ------------- | --------- |
  | Type:         | int       |
  | Default:      | 0         |
  | Valid Values: |           |
  | Importance:   | high      |
  | Update Mode:  | read-only |

- #### [offsets.topic.num.partitions](https://kafka.apache.org/documentation/#brokerconfigs_offsets.topic.num.partitions)
  
  The number of partitions for the offset commit topic (should not change after deployment).
  
  |               |           |
  | ------------- | --------- |
  | Type:         | int       |
  | Default:      | 50        |
  | Valid Values: | [1,...]   |
  | Importance:   | high      |
  | Update Mode:  | read-only |

- #### [offsets.topic.replication.factor](https://kafka.apache.org/documentation/#brokerconfigs_offsets.topic.replication.factor)
  
  The replication factor for the offsets topic (set higher to ensure availability). Internal topic creation will fail until the cluster size meets this replication factor requirement.
  
  |               |           |
  | ------------- | --------- |
  | Type:         | short     |
  | Default:      | 3         |
  | Valid Values: | [1,...]   |
  | Importance:   | high      |
  | Update Mode:  | read-only |

- #### [offsets.topic.segment.bytes](https://kafka.apache.org/documentation/#brokerconfigs_offsets.topic.segment.bytes)
  
  The offsets topic segment bytes should be kept relatively small in order to facilitate faster log compaction and cache loads.
  
  |               |                           |
  | ------------- | ------------------------- |
  | Type:         | int                       |
  | Default:      | 104857600 (100 mebibytes) |
  | Valid Values: | [1,...]                   |
  | Importance:   | high                      |
  | Update Mode:  | read-only                 |

- #### [process.roles](https://kafka.apache.org/documentation/#brokerconfigs_process.roles)
  
  The roles that this process plays: 'broker', 'controller', or 'broker,controller' if it is both. This configuration is only applicable for clusters in KRaft (Kafka Raft) mode (instead of ZooKeeper). Leave this config undefined or empty for ZooKeeper clusters.
  
  |               |                      |
  | ------------- | -------------------- |
  | Type:         | list                 |
  | Default:      | ""                   |
  | Valid Values: | [broker, controller] |
  | Importance:   | high                 |
  | Update Mode:  | read-only            |

- #### [queued.max.requests](https://kafka.apache.org/documentation/#brokerconfigs_queued.max.requests)
  
  The number of queued requests allowed for data-plane, before blocking the network threads
  
  |               |           |
  | ------------- | --------- |
  | Type:         | int       |
  | Default:      | 500       |
  | Valid Values: | [1,...]   |
  | Importance:   | high      |
  | Update Mode:  | read-only |

- #### [replica.fetch.min.bytes](https://kafka.apache.org/documentation/#brokerconfigs_replica.fetch.min.bytes)
  
  Minimum bytes expected for each fetch response. If not enough bytes, wait up to `replica.fetch.wait.max.ms` (broker config).
  
  |               |           |
  | ------------- | --------- |
  | Type:         | int       |
  | Default:      | 1         |
  | Valid Values: |           |
  | Importance:   | high      |
  | Update Mode:  | read-only |

- #### [replica.fetch.wait.max.ms](https://kafka.apache.org/documentation/#brokerconfigs_replica.fetch.wait.max.ms)
  
  The maximum wait time for each fetcher request issued by follower replicas. This value should always be less than the replica.lag.time.max.ms at all times to prevent frequent shrinking of ISR for low throughput topics
  
  |               |           |
  | ------------- | --------- |
  | Type:         | int       |
  | Default:      | 500       |
  | Valid Values: |           |
  | Importance:   | high      |
  | Update Mode:  | read-only |

- #### [replica.high.watermark.checkpoint.interval.ms](https://kafka.apache.org/documentation/#brokerconfigs_replica.high.watermark.checkpoint.interval.ms)
  
  The frequency with which the high watermark is saved out to disk
  
  |               |                  |
  | ------------- | ---------------- |
  | Type:         | long             |
  | Default:      | 5000 (5 seconds) |
  | Valid Values: |                  |
  | Importance:   | high             |
  | Update Mode:  | read-only        |

- #### [replica.lag.time.max.ms](https://kafka.apache.org/documentation/#brokerconfigs_replica.lag.time.max.ms)
  
  If a follower hasn't sent any fetch requests or hasn't consumed up to the leaders log end offset for at least this time, the leader will remove the follower from isr
  
  |               |                    |
  | ------------- | ------------------ |
  | Type:         | long               |
  | Default:      | 30000 (30 seconds) |
  | Valid Values: |                    |
  | Importance:   | high               |
  | Update Mode:  | read-only          |

- #### [replica.socket.receive.buffer.bytes](https://kafka.apache.org/documentation/#brokerconfigs_replica.socket.receive.buffer.bytes)
  
  The socket receive buffer for network requests to the leader for replicating data
  
  |               |                      |
  | ------------- | -------------------- |
  | Type:         | int                  |
  | Default:      | 65536 (64 kibibytes) |
  | Valid Values: |                      |
  | Importance:   | high                 |
  | Update Mode:  | read-only            |

- #### [replica.socket.timeout.ms](https://kafka.apache.org/documentation/#brokerconfigs_replica.socket.timeout.ms)
  
  The socket timeout for network requests. Its value should be at least replica.fetch.wait.max.ms
  
  |               |                    |
  | ------------- | ------------------ |
  | Type:         | int                |
  | Default:      | 30000 (30 seconds) |
  | Valid Values: |                    |
  | Importance:   | high               |
  | Update Mode:  | read-only          |

- #### [request.timeout.ms](https://kafka.apache.org/documentation/#brokerconfigs_request.timeout.ms)
  
  The configuration controls the maximum amount of time the client will wait for the response of a request. If the response is not received before the timeout elapses the client will resend the request if necessary or fail the request if retries are exhausted.
  
  |               |                    |
  | ------------- | ------------------ |
  | Type:         | int                |
  | Default:      | 30000 (30 seconds) |
  | Valid Values: |                    |
  | Importance:   | high               |
  | Update Mode:  | read-only          |

- #### [sasl.mechanism.controller.protocol](https://kafka.apache.org/documentation/#brokerconfigs_sasl.mechanism.controller.protocol)
  
  SASL mechanism used for communication with controllers. Default is GSSAPI.
  
  |               |           |
  | ------------- | --------- |
  | Type:         | string    |
  | Default:      | GSSAPI    |
  | Valid Values: |           |
  | Importance:   | high      |
  | Update Mode:  | read-only |

- #### [socket.receive.buffer.bytes](https://kafka.apache.org/documentation/#brokerconfigs_socket.receive.buffer.bytes)
  
  The SO_RCVBUF buffer of the socket server sockets. If the value is -1, the OS default will be used.
  
  |               |                        |
  | ------------- | ---------------------- |
  | Type:         | int                    |
  | Default:      | 102400 (100 kibibytes) |
  | Valid Values: |                        |
  | Importance:   | high                   |
  | Update Mode:  | read-only              |

- #### [socket.request.max.bytes](https://kafka.apache.org/documentation/#brokerconfigs_socket.request.max.bytes)
  
  The maximum number of bytes in a socket request
  
  |               |                           |
  | ------------- | ------------------------- |
  | Type:         | int                       |
  | Default:      | 104857600 (100 mebibytes) |
  | Valid Values: | [1,...]                   |
  | Importance:   | high                      |
  | Update Mode:  | read-only                 |

- #### [socket.send.buffer.bytes](https://kafka.apache.org/documentation/#brokerconfigs_socket.send.buffer.bytes)
  
  The SO_SNDBUF buffer of the socket server sockets. If the value is -1, the OS default will be used.
  
  |               |                        |
  | ------------- | ---------------------- |
  | Type:         | int                    |
  | Default:      | 102400 (100 kibibytes) |
  | Valid Values: |                        |
  | Importance:   | high                   |
  | Update Mode:  | read-only              |

- #### [transaction.max.timeout.ms](https://kafka.apache.org/documentation/#brokerconfigs_transaction.max.timeout.ms)
  
  The maximum allowed timeout for transactions. If a client’s requested transaction time exceed this, then the broker will return an error in InitProducerIdRequest. This prevents a client from too large of a timeout, which can stall consumers reading from topics included in the transaction.
  
  |               |                     |
  | ------------- | ------------------- |
  | Type:         | int                 |
  | Default:      | 900000 (15 minutes) |
  | Valid Values: | [1,...]             |
  | Importance:   | high                |
  | Update Mode:  | read-only           |

- #### [transaction.state.log.load.buffer.size](https://kafka.apache.org/documentation/#brokerconfigs_transaction.state.log.load.buffer.size)
  
  Batch size for reading from the transaction log segments when loading producer ids and transactions into the cache (soft-limit, overridden if records are too large).
  
  |               |           |
  | ------------- | --------- |
  | Type:         | int       |
  | Default:      | 5242880   |
  | Valid Values: | [1,...]   |
  | Importance:   | high      |
  | Update Mode:  | read-only |

- #### [transaction.state.log.min.isr](https://kafka.apache.org/documentation/#brokerconfigs_transaction.state.log.min.isr)
  
  The minimum number of replicas that must acknowledge a write to transaction topic in order to be considered successful.
  
  |               |           |
  | ------------- | --------- |
  | Type:         | int       |
  | Default:      | 2         |
  | Valid Values: | [1,...]   |
  | Importance:   | high      |
  | Update Mode:  | read-only |

- #### [transaction.state.log.num.partitions](https://kafka.apache.org/documentation/#brokerconfigs_transaction.state.log.num.partitions)
  
  The number of partitions for the transaction topic (should not change after deployment).
  
  |               |           |
  | ------------- | --------- |
  | Type:         | int       |
  | Default:      | 50        |
  | Valid Values: | [1,...]   |
  | Importance:   | high      |
  | Update Mode:  | read-only |

- #### [transaction.state.log.replication.factor](https://kafka.apache.org/documentation/#brokerconfigs_transaction.state.log.replication.factor)
  
  The replication factor for the transaction topic (set higher to ensure availability). Internal topic creation will fail until the cluster size meets this replication factor requirement.
  
  |               |           |
  | ------------- | --------- |
  | Type:         | short     |
  | Default:      | 3         |
  | Valid Values: | [1,...]   |
  | Importance:   | high      |
  | Update Mode:  | read-only |

- #### [transaction.state.log.segment.bytes](https://kafka.apache.org/documentation/#brokerconfigs_transaction.state.log.segment.bytes)
  
  The transaction topic segment bytes should be kept relatively small in order to facilitate faster log compaction and cache loads
  
  |               |                           |
  | ------------- | ------------------------- |
  | Type:         | int                       |
  | Default:      | 104857600 (100 mebibytes) |
  | Valid Values: | [1,...]                   |
  | Importance:   | high                      |
  | Update Mode:  | read-only                 |

- #### [transactional.id.expiration.ms](https://kafka.apache.org/documentation/#brokerconfigs_transactional.id.expiration.ms)
  
  The time in ms that the transaction coordinator will wait without receiving any transaction status updates for the current transaction before expiring its transactional id. Transactional IDs will not expire while a the transaction is still ongoing.
  
  |               |                    |
  | ------------- | ------------------ |
  | Type:         | int                |
  | Default:      | 604800000 (7 days) |
  | Valid Values: | [1,...]            |
  | Importance:   | high               |
  | Update Mode:  | read-only          |

- #### [unclean.leader.election.enable](https://kafka.apache.org/documentation/#brokerconfigs_unclean.leader.election.enable)
  
  Indicates whether to enable replicas not in the ISR set to be elected as leader as a last resort, even though doing so may result in data loss
  
  Note: In KRaft mode, when enabling this config dynamically, it needs to wait for the unclean leader election thread to trigger election periodically (default is 5 minutes). Please run `kafka-leader-election.sh` with `unclean` option to trigger the unclean leader election immediately if needed.
  
  |               |              |
  | ------------- | ------------ |
  | Type:         | boolean      |
  | Default:      | false        |
  | Valid Values: |              |
  | Importance:   | high         |
  | Update Mode:  | cluster-wide |

- #### [zookeeper.connect](https://kafka.apache.org/documentation/#brokerconfigs_zookeeper.connect)
  
  Specifies the ZooKeeper connection string in the form `hostname:port` where host and port are the host and port of a ZooKeeper server. To allow connecting through other ZooKeeper nodes when that ZooKeeper machine is down you can also specify multiple hosts in the form `hostname1:port1,hostname2:port2,hostname3:port3`.  
  The server can also have a ZooKeeper chroot path as part of its ZooKeeper connection string which puts its data under some path in the global ZooKeeper namespace. For example to give a chroot path of `/chroot/path` you would give the connection string as `hostname1:port1,hostname2:port2,hostname3:port3/chroot/path`.
  
  |               |           |
  | ------------- | --------- |
  | Type:         | string    |
  | Default:      | null      |
  | Valid Values: |           |
  | Importance:   | high      |
  | Update Mode:  | read-only |

- #### [zookeeper.connection.timeout.ms](https://kafka.apache.org/documentation/#brokerconfigs_zookeeper.connection.timeout.ms)
  
  The max time that the client waits to establish a connection to ZooKeeper. If not set, the value in zookeeper.session.timeout.ms is used
  
  |               |           |
  | ------------- | --------- |
  | Type:         | int       |
  | Default:      | null      |
  | Valid Values: |           |
  | Importance:   | high      |
  | Update Mode:  | read-only |

- #### [zookeeper.max.in.flight.requests](https://kafka.apache.org/documentation/#brokerconfigs_zookeeper.max.in.flight.requests)
  
  The maximum number of unacknowledged requests the client will send to ZooKeeper before blocking.
  
  |               |           |
  | ------------- | --------- |
  | Type:         | int       |
  | Default:      | 10        |
  | Valid Values: | [1,...]   |
  | Importance:   | high      |
  | Update Mode:  | read-only |

- #### [zookeeper.metadata.migration.enable](https://kafka.apache.org/documentation/#brokerconfigs_zookeeper.metadata.migration.enable)
  
  Enable ZK to KRaft migration
  
  |               |           |
  | ------------- | --------- |
  | Type:         | boolean   |
  | Default:      | false     |
  | Valid Values: |           |
  | Importance:   | high      |
  | Update Mode:  | read-only |

- #### [zookeeper.session.timeout.ms](https://kafka.apache.org/documentation/#brokerconfigs_zookeeper.session.timeout.ms)
  
  Zookeeper session timeout
  
  |               |                    |
  | ------------- | ------------------ |
  | Type:         | int                |
  | Default:      | 18000 (18 seconds) |
  | Valid Values: |                    |
  | Importance:   | high               |
  | Update Mode:  | read-only          |
